---
title: "Análise preliminar: planos de saúde"
author: "Julio Trecenti"
date: "April 26, 2017"
output: html_document
---

# Introdução

Nessa análise preliminar consideramos acórdãos do TJSP com assunto "Planos de saúde". Esse filtro não é ideal para a análise pois existem processos envolvendo planos de saúde classificados em outros assuntos. No entanto, para um primeiro estudo esse escopo é suficiente.

A análise passa por três etapas, descritas abaixo.

- **Download**. Utilizamos os pacotes `esaj` e `tjsp` para baixar listas de processos automaticamente do TJSP.
- **Limpeza**. Seleção e transformação das variáveis.
- **Análise descritiva**. Alguns gráficos e tabelas sobre os casos baixados.

## Pacotes utilizados

Esse relatório foi construído em **RMarkdown** e é completamente reprodutível. Os pacotes utilizados para as análises estão listados abaixo:

```{r warning=FALSE, message=FALSE}
library(tidyverse)
library(stringr)
library(forcats)
library(lubridate)
library(esaj) # github.com/courtsbr/esaj
library(tjsp) # github.com/courtsbr/tjsp
```

# Download

Lista de assuntos do TJSP na Consulta de Julgados do Segundo Grau:

```{r}
# assuntos <- cjsg_tabs('assuntos')
# write_rds(assuntos, 'assuntos.rds', compress = 'bz')
assuntos <- read_rds('assuntos.rds')
```

Agora pegamos apenas o assunto de planos de saúde.

```{r}
cod_assuntos <- assuntos %>% 
  filter(str_detect(titulo_leaf, 'Planos de S|SUS|M[ée]dic'),
         !str_detect(titulo0, 'ANTIGO|PENAL|CRIAN[CÇ]A')) %>% 
  with(cod_leaf) %>% 
  glue::collapse(',')
```

Abrimos uma sessão de conexão com o TJSP e inserimos as informações de pesquisa (somente os assuntos).

```{r}
s <- cjsg_session()
parms <- cjsg_parms(s, assunto = cod_assuntos)
```

O número de documentos no resultado da pesquisa é dado por `cjsg_npags()`:

```{r message=FALSE}
npags <- cjsg_npags(s, parms = parms)
npags
```

A quantidade `r npags` é muito grande! Vamos baixar apenas as primeiras mil páginas (os documentos estão ordenados por data de publicação do acórdão, das mais recentes para as mais antigas.) O download demorou aproximadamente 40 minutos.

```{r eval=FALSE}
# nao rodar! demora
d_result <- cjsg(s, parms = parms, path = 'data-raw/cjsg', max_pag = 1000L)
```

--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------

**Update**: Baixando todas as páginas, mas um ano por vez.

```{r}
anos <- tibble(
  anos_ini = ymd('2007-01-01') + years(0:10),
  anos_fim = ymd('2008-01-01') + years(0:10) - days(1)
) %>% 
  transpose() %>% 
  simplify_all() %>% 
  map(~as.character(as.Date(.x, origin = '1970-01-01'))) %>% 
  rev() %>% 
  tail(1)


p <- map_dbl(anos, ~{
  msg <- glue::glue('\n{year(.x[1])}-------------------\n')
  cat(msg, sep = '\n')
  s <- cjsg_session()
  parms <- cjsg_parms(s, assunto = cod_assuntos, 
                      data_inicial_reg = .x[1],
                      data_final_reg = .x[2])
  # d_result <- cjsg(s, parms = parms, 
  #                  path = glue::glue('data-raw/cjsg{year(.x[1])}'), 
  #                  max_pag = Inf)
  suppressMessages(cjsg_npags(s, parms = parms))
})
p

np <- map_dbl(dir('data-raw', pattern = '[0-9]', full.names = TRUE), 
              ~length(dir(.x))) %>% 
  rev()
p - np

all_pages <- dir('data-raw', pattern = '[0-9]', full.names = TRUE) %>% 
  map(dir, full.names = TRUE) %>% 
  flatten_chr()

dados <- parse_cjsg(all_pages)
```


--------------------------------------------------------------------------------

# cposg

```{r}
dados <- readRDS('data-raw/cjsg.rds')
d_cjsg <- dados %>% 
  mutate(data_registro = dmy(data_registro),
         ano_registro = year(data_registro))


cposg_um <- function (p, path, ow) {
  if (runif(1) < .01) cat(length(dir(path)), '\n')
  arq <- sprintf("%s/%s.html", path, p)
  if (!file.exists(arq) || ow) {
    httr::GET("https://esaj.tjsp.jus.br/cposg/search.do",
              query = tjsp:::dados_cposg(p), 
              config = httr::config(ssl_verifypeer = FALSE), 
      httr::write_disk(arq, overwrite = ow))
    tibble::tibble(result = "OK")
  } else {
    tibble::tibble(result = "já existe")
  }
}

result <- purrr::map_df(2013:2008, ~{
  cat(glue::glue('\n\n{.x}-------------------\n\n'), sep = '\n')
  pasta <- glue::glue('data-raw/cpopg{.x}')
  dir.create(pasta, recursive = TRUE, showWarnings = FALSE)
  processos <- d_cjsg %>% 
    filter(ano_registro == .x) %>% 
    distinct(n_processo) %>% 
    with(n_processo) %>% 
    str_replace_all('[^0-9]', '')
  cat('Total: ', length(processos), '\n\n')
  cl <- parallel::makeCluster(parallel::detectCores(), outfile = "")
  doParallel::registerDoParallel(cl)
  safe_cposg <- possibly(cposg_um, tibble(result = 'erro'))
  l <- plyr::llply(processos, safe_cposg, path = pasta, ow = FALSE)
  parallel::stopCluster(cl)
  bind_rows(l)
}, .id = 'ano')

```



```{r}
decisoes_cposg_um <- function(html) {
  xpath <- '(//table[@width="98%" and @align="center"])[last()]'
  r <- rvest::html_node(html, xpath = xpath)
  tab <- rvest::html_table(r)
  names(tab) <- c('data', 'situacao', 'decisao')
  tab$result <- 'OK'
  return(tab)
}

arqs <- c('data-raw/cpopg2017',
          'data-raw/cpopg2016',
          'data-raw/cpopg2015') %>% 
  map(dir, full.names = TRUE, pattern = 'html$') %>% 
  unlist()
a <- arqs
p <- progress::progress_bar$new(total = length(a))

f <- function(.x) {
  rds <- stringr::str_replace(.x, 'html$', 'rds')
  if (!file.exists(rds)) {
    html <- xml2::read_html(.x)
    infos <- esaj:::parse_cpopg_infos_(html)
    partes <- esaj:::parse_cpopg_partes_(html)
    decisoes <- decisoes_cposg_um(html)
    result <- list(infos = infos, partes = partes, decisoes = decisoes)
    saveRDS(result, rds)
  } else {
    result <- tibble(result = 'ja foi')
  }
  p$tick()
  result
}
ff <- purrr::possibly(f, tibble(result = 'erro'))
result <- purrr::map_df(a, ff, .id = '.id')
```

```{r}
d <- 'data-raw/cpopg2016' %>% 
  dir(full.names = TRUE, pattern = '\\.rds$') %>% 
  enframe('id', 'arq') %>% 
  group_by(id, arq) %>% 
  do(aff = readRDS(.$arq)) %>% 
  ungroup() %>% 
  as_tibble()

```

--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------

Agora, vamos ler o conteúdo desses arquivos HTML. Para isso, utilizamos `cjsg_parse`:

```{r eval=FALSE}
# nao rodar! demora
arqs <- dir('data-raw/cjsg', full.names = TRUE)
d_cjsg <- parse_cjsg(arqs) 
write_rds(d_cjsg, 'd_cjsg.rds', compress = 'bz')
```

```{r}
d_cjsg <- read_rds('d_cjsg.rds')
d_cjsg
```

Pronto! Temos uma base de dados com `r nrow(d_cjsg)`. Essa base de dados tem as seguintes informações:

- `arq`: caminho do aquivo HTML.
- `id`: id do resultado.
- `cd_acordao`: código único do acórdão.
- `n_processo`: número do processo (um processo pode ter mais de um acórdão).
- `comarca`: comarca de origem do processo.
- `data_julgamento`: data de julgamento do processo.
- `data_registro`: data de registro da decisão (essa é a data usada para indexar as decisões.)
- `ementa`: ementa do processo.
- `orgao_julgador`: nome do órgão julgador.
- `relatora`: relator(a) do processo.
- `classe_assunto`: classe e assunto.
- `txt_ementa`: texto da ementa (geralmente igual à `ementa`.)
- `result`: indicador de leitura correta da página (geralmente tudo OK.)
- `outros_numeros`: outros números do processo.

# Limpeza

Vamos utilizar só uma parte dessas colunas. Para limpar os dados e obter a base `d_tidy`, rodamos o seguinte algoritmo.

```{r}
d_tidy <- d_cjsg %>% 
  distinct(cd_acordao, .keep_all = TRUE) %>% 
  select(cd_acordao, n_processo:classe_assunto) %>% 
  separate(classe_assunto, c('classe', 'assunto'), sep = ' / ',
           extra = 'merge', fill = 'left') %>% 
  mutate_at(vars(starts_with('data_')), dmy)
```

A base total contém 20.000 acórdãos de 17.289 processos.

# Análise descritiva

## Principais classes

```{r}
d_tidy %>% 
  mutate(classe = fct_lump(classe, prop = 0.006, 
                           other_level = 'Outros')) %>% 
  count(classe, sort = TRUE) %>% 
  mutate(prop = n/sum(n)) %>% 
  janitor::add_totals_row() %>% 
  mutate(prop = scales::percent(prop)) %>% 
  knitr::kable()
```

## Evolução no tempo 

(tomar cuidado ao interpretar esse gráfico, pois não baixamos todos os casos!)

```{r}
d_tidy %>% 
  mutate(classe = fct_lump(classe, prop = 0.1, other_level = 'Outros')) %>% 
  mutate(mes_decisao = floor_date(data_julgamento, 'month')) %>% 
  filter(mes_decisao > '2016-05-01') %>% 
  count(mes_decisao) %>% 
  ggplot(aes(x = mes_decisao, y = n)) +
  geom_line() +
  geom_point() +
  labs(x = 'Mês da decisão', 'Quantidade de decisões') +
  theme_gray(15)
```

## Comarcas

Nesse caso seria interessante dividir pela população.

```{r}
d_tidy %>% 
  mutate(comarca = comarca %>% 
           fct_infreq() %>% 
           fct_lump(prop = 0.01, other_level = 'Outros')) %>%
  count(comarca) %>% 
  mutate(prop = n / sum(n)) %>% 
  janitor::add_totals_row() %>% 
  mutate(prop = scales::percent(prop)) %>% 
  knitr::kable()
```

## Relatores

No futuro, seremos capazes de analisar a taxa de decisões favoráveis / desfavoráveis por relator e câmara.

```{r}
d_tidy %>% 
  mutate(relatora = relatora %>% 
           fct_infreq() %>% 
           fct_lump(prop = 0.02, other_level = 'Outros')) %>%
  count(relatora) %>% 
  mutate(prop = n / sum(n)) %>% 
  janitor::add_totals_row() %>% 
  mutate(prop = scales::percent(prop)) %>% 
  knitr::kable()
```


## Exemplos de textos

```{r}
set.seed(1)
d_tidy %>% 
  sample_n(1) %>% 
  with(ementa) %>% 
  cat()
```


```{r results='asis'}
set.seed(1)
d_tidy %>% 
  sample_n(5) %>% 
  with(ementa) %>% 
  cat(sep = paste0('\n\n', strrep('-', 80), '\n\n'))

```



