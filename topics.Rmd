---
title: "Topic models"
date: "May 24, 2017"
output: 
  pdf_document:
    df_print: kable
---

--------------------------------------------------------------------------------

Rodei o modelo numa amostra de 5000 decisões. O algorito de stemming que estou usando é muito pesado e não generaliza. Vou rodar um modelão com as 130k+ decisões que baixei, mas acho que nao vai rodar a tempo. 

```{r}
library(tidyverse)
library(lubridate)
library(topicmodels)
library(ptwikiwords)
library(ptstem)
library(rslp)

d_txt <- readRDS('data-raw/cjsg.rds') %>% 
  filter(!is.na(ementa)) %>% 
  filter(!str_detect(tolower(classe_assunto), 'embargo|agravo')) %>% 
  mutate(data_registro = dmy(data_registro)) %>% 
  arrange(desc(data_registro)) %>% 
  filter(year(data_registro) >= 2015)

set.seed(1)
d_amostra <- d_txt %>% sample_n(5000) 
```

--------------------------------------------------------------------------------

Aqui temos uma lista de banned word por vários motivos

```{r, eval=FALSE}
pt_stops <- tm::stopwords('pt-br')
pt_direito     <- c("ação", "acolhimento", "acórdão",
                    "advocatício", "advogado", 
                    "agravo", "alçada", "alegação", 
                    "apelo", "apelação", "apenso",
                    "aplicação",
                    "artigo", "autos", "autor", "ato",
                    "causa", "câmara", "cível", "civil", 
                    "código", "comarca", "comprovação", "condenação",
                    "dano", "data",
                    "decisão", "declaração", "decorrente", 
                    "defesa", "dever", "desembargador", "devolução",
                    "diante", "direito",
                    "embargo", "ementa", "estado", "exposto", 
                    "fato", "fundamento",
                    "honorários", "inicial",
                    "improcedência", "improcedente", "improvimento", 
                    "indevido",
                    "instância", "instrumento",
                    "interposto",
                    "judiciário", 
                    "juiz", "julgamento", 
                    "jurídico", "jurisprudência", "juros", 
                    "justiça",
                    "lei", "lide", 
                    "matéria", "materialmente", "mérito", 
                    "monocrático", "mora",
                    "nome",
                    "objeto",
                    "parcial", "parte", "passivo",
                    "pedido", "petição",
                    "pleitear", "poder",
                    "prejuízo", "preposto", "presidente",
                    "pretensão", "previsto",
                    "procedência", "procedente", 
                    "processo", "processual",
                    "provido", "provimento",
                    "razão",
                    "ré", "recurso", 
                    "relator", "relatório", 
                    "réu", "revisão",
                    "sentença", "sucumbência", 
                    "tribunal", "turma", 
                    "unânime", "valor", "vara", "vítima")

pt_direito_abr <- c("art", "cpc", "fls", "n", "tjsp")

pt_wiki <- ptwikiwords %>% 
  with(word) %>% 
  head(1000)

banned_raw <- c(pt_stops, pt_direito, pt_direito_abr, pt_wiki) %>% 
  unique()

banned <- banned_raw %>% 
  ptstem_words(complete = FALSE) %>% 
  unique() %>% 
  abjutils::rm_accent()


```

--------------------------------------------------------------------------------

Algoritmo de limpar o texto

```{r}
clean_txt <- function(x, banned, banned_raw, wt = tm::weightTf) {
  x %>% 
    str_to_lower() %>%
    str_replace_all('[\r\t\n ]+', ' ') %>% 
    str_replace_all('º', '') %>% 
    str_replace_all('([a-z§.]) ([0-9])', '\\1_\\2') %>% 
    str_replace_all('[-–".$,():]', '') %>% 
    str_replace_all('([0-9]) (§|e_|pará)', '\\1_\\2') %>%
    str_replace_all('[\r\t\n ]+', ' ') %>% 
    ptstem(n_char = 4, 
           algorithm = 'hunspell',
           complete = FALSE, 
           ignore = 'art.*|lei_.*|parág.*') %>%
    str_split(' +') %>%
    map_df(enframe, .id = '.id') %>% 
    filter(!value %in% banned_raw) %>% 
    mutate(value = abjutils::rm_accent(value)) %>% 
    filter(!value %in% banned) %>% 
    filter(!value %in% abjutils::rm_accent(banned_raw)) %>% 
    count(.id, value) %>% 
    ungroup() %>% 
    tidytext::cast_dtm(.id, value, n, weighting = wt)
}
```

```{r, eval=FALSE}
bag_dtm <- d_amostra %>% 
  with(ementa) %>% 
  clean_txt(banned, banned_raw, wt = tm::weightTf)
saveRDS(bag_dtm, 'bag_dtm2.rds')

lda5 <- LDA(bag_dtm, k = 5, control = list(seed = 1234))
lda4 <- LDA(bag_dtm, k = 4, control = list(seed = 1234))
lda3 <- LDA(bag_dtm, k = 3, control = list(seed = 1234))
lda2 <- LDA(bag_dtm, k = 2, control = list(seed = 1234))

lda <- list(lda5, lda4, lda3, lda2)
saveRDS(lda, 'lda.rds')
```

```{r}
bag_dtm <- readRDS('bag_dtm.rds')
lda <- readRDS('lda.rds')
lda_print <- function(lda, n_terms = 10) {
  lda %>% 
    tidytext::tidy() %>% 
    group_by(topic) %>%
    top_n(n_terms, beta) %>%
    ungroup() %>%
    arrange(topic, -beta) %>% 
    group_by(topic) %>%
    mutate(id = 1:n()) %>% 
    ungroup() %>% 
    select(-beta) %>% 
    spread(topic, term) %>% 
    head(n_terms)
}
```

# Resultados dos modelos de tópicos

Essas tabelas mostram as principais palavras encontradas para cada modelo LDA ajustado (com 5 tópicos, 4 tópicos, 3 tópicos, 2 tópicos).

5 topicos

```{r}
lda_print(lda[[1]])
```

4 topicos

```{r}
lda_print(lda[[2]])
```

3 topicos

```{r}
lda_print(lda[[3]])
```

2 topicos

```{r}
lda_print(lda[[4]])
```

# Cruzando tópicos com classe/assunto

Essas tabelas mostram quais são as 5 combinações de classe/assunto mais frequentes em cada tópico, considerando cada modelo de tópicos (com 5 tópicos, 4 tópicos, etc).

```{r}
d_lda <- d_amostra %>% 
  mutate(lda5 = topics(lda[[1]]),
         lda4 = topics(lda[[2]]),
         lda3 = topics(lda[[3]]),
         lda2 = topics(lda[[4]]))
```

LDA com 5 grupos

```{r}
d_lda %>% 
  count(lda5, classe_assunto) %>% 
  arrange(lda5, desc(n)) %>% 
  top_n(5)
```

LDA com 4 grupos

```{r}
d_lda %>% 
  count(lda4, classe_assunto) %>% 
  arrange(lda4, desc(n)) %>% 
  top_n(5)
```

```{r}
d_lda %>% 
  count(lda3, classe_assunto) %>% 
  arrange(lda3, desc(n)) %>% 
  top_n(5)

```

```{r}
d_lda %>% 
  count(lda2, classe_assunto) %>% 
  arrange(lda2, desc(n)) %>% 
  top_n(5)
```

